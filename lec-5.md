# Lecture 4. Introduction to Reinforcement Learning

## 질문
- p4: $\sum_i$는 현재정책에서 얻은 모든 샘플에 대해 더한다는 의미!
- p6: 그래디언트 유도과정 중에 초기상태와 전이확률이 없어지는 이유는?
- p7: REINFORCE 알고리즘 2번 라인에서 $\sum_i$가 빠져야 하지 않을까? 어쩌면 현재까지 얻어진 모든 에피소드를 더하는걸까?
- p11: 하나의 에피소드가 끝나면 policy gradient를 이용해 정책을 업데이트 

- p9: 
- p10: ML식은 어디서 왔는가?
- p13: POMDP에서 policy gradient를 그대로 사용해도 될까?
- p14: policy gradient의 문제점은 무엇인가? 분산이 큰 이유는? (무엇의 분산인가?)

## 요약


